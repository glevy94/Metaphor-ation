{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask the word at the given index\n",
    "def mask_word(sentence, index):\n",
    "    words = sentence.split()  # Split the sentence into words\n",
    "    if 0 <= index < len(words):  \n",
    "        words[index] = '[MASK]'  # Replace the word at the specified index\n",
    "    return ' '.join(words)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  label                                           sentence   pos  \\\n",
      "0    373      0  Care Enterprises Inc., a financially troubled ...  VERB   \n",
      "1    374      1  The GAO was also to examine if the law has cau...  VERB   \n",
      "2    375      1   \" Without voodoo, we would drown in our misery.'  VERB   \n",
      "3    376      0  Twenty- eight thousand buildings were leveled ...  VERB   \n",
      "4    377      0  Twelve- year- old Peter Reaves of Pittsburgh t...  VERB   \n",
      "\n",
      "   v_index  \n",
      "0       33  \n",
      "1        5  \n",
      "2        5  \n",
      "3       28  \n",
      "4       13  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>data_set</th>\n",
       "      <th>masked_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The GAO was also to examine if the law has cau...</td>\n",
       "      <td>trofi</td>\n",
       "      <td>The GAO was also to [MASK] if the law has caus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\" Without voodoo, we would drown in our misery.'</td>\n",
       "      <td>trofi</td>\n",
       "      <td>\" Without voodoo, we would [MASK] in our misery.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mrs. Bush, who disdains what she calls fake pu...</td>\n",
       "      <td>trofi</td>\n",
       "      <td>Mrs. Bush, who disdains what she calls fake pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\" You lose elections if you touch these things.'</td>\n",
       "      <td>trofi</td>\n",
       "      <td>\" You lose elections if you [MASK] these things.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Industry watchers respect Genentech for pumpin...</td>\n",
       "      <td>trofi</td>\n",
       "      <td>Industry watchers respect Genentech for [MASK]...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence data_set  \\\n",
       "1  The GAO was also to examine if the law has cau...    trofi   \n",
       "2   \" Without voodoo, we would drown in our misery.'    trofi   \n",
       "5  Mrs. Bush, who disdains what she calls fake pu...    trofi   \n",
       "7   \" You lose elections if you touch these things.'    trofi   \n",
       "8  Industry watchers respect Genentech for pumpin...    trofi   \n",
       "\n",
       "                                     masked_sentence  \n",
       "1  The GAO was also to [MASK] if the law has caus...  \n",
       "2  \" Without voodoo, we would [MASK] in our misery.'  \n",
       "5  Mrs. Bush, who disdains what she calls fake pu...  \n",
       "7  \" You lose elections if you [MASK] these things.'  \n",
       "8  Industry watchers respect Genentech for [MASK]...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"data/0000.parquet\")\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Filter for rows where label == 1 and apply masking\n",
    "df_filtered = df[df['label'] == 1].copy()  # Copy rows where label == 1\n",
    "df_filtered['masked_sentence'] = df_filtered.apply(\n",
    "    lambda row: mask_word(row['sentence'], row['v_index']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_filtered['data_set'] = \"trofi\"\n",
    "\n",
    "trofi_df = df_filtered[['sentence', 'data_set', 'masked_sentence']]\n",
    "trofi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        arg1  arg2    verb                                           sentence  \\\n",
      "0  knowledge   NaN  absorb  He absorbed the knowledge or beliefs of his tr...   \n",
      "1       cost   NaN  absorb           He absorbed the costs for the accident .   \n",
      "2        tax   NaN  absorb  The sales tax is absorbed into the state incom...   \n",
      "3  immigrant   NaN  absorb  The immigrants were quickly absorbed into soci...   \n",
      "4   interest   NaN  absorb  Her interest in butterflies absorbs her comple...   \n",
      "\n",
      "   verb_idx  label  \n",
      "0         1      1  \n",
      "1         1      1  \n",
      "2         4      1  \n",
      "3         4      1  \n",
      "4         4      1  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>data_set</th>\n",
       "      <th>masked_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He absorbed the knowledge or beliefs of his tr...</td>\n",
       "      <td>moh_x</td>\n",
       "      <td>He [MASK] the knowledge or beliefs of his tribe .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He absorbed the costs for the accident .</td>\n",
       "      <td>moh_x</td>\n",
       "      <td>He [MASK] the costs for the accident .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The sales tax is absorbed into the state incom...</td>\n",
       "      <td>moh_x</td>\n",
       "      <td>The sales tax is [MASK] into the state income ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The immigrants were quickly absorbed into soci...</td>\n",
       "      <td>moh_x</td>\n",
       "      <td>The immigrants were quickly [MASK] into society .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Her interest in butterflies absorbs her comple...</td>\n",
       "      <td>moh_x</td>\n",
       "      <td>Her interest in butterflies [MASK] her complet...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence data_set  \\\n",
       "0  He absorbed the knowledge or beliefs of his tr...    moh_x   \n",
       "1           He absorbed the costs for the accident .    moh_x   \n",
       "2  The sales tax is absorbed into the state incom...    moh_x   \n",
       "3  The immigrants were quickly absorbed into soci...    moh_x   \n",
       "4  Her interest in butterflies absorbs her comple...    moh_x   \n",
       "\n",
       "                                     masked_sentence  \n",
       "0  He [MASK] the knowledge or beliefs of his tribe .  \n",
       "1             He [MASK] the costs for the accident .  \n",
       "2  The sales tax is [MASK] into the state income ...  \n",
       "3  The immigrants were quickly [MASK] into society .  \n",
       "4  Her interest in butterflies [MASK] her complet...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/MOH-X_formatted_svo.csv\")\n",
    "print(df.head())\n",
    "\n",
    "# Filter for rows where label == 1 and apply masking\n",
    "df_filtered = df[df['label'] == 1].copy()  # Copy rows where label == 1\n",
    "df_filtered['masked_sentence'] = df_filtered.apply(\n",
    "    lambda row: mask_word(row['sentence'], row['verb_idx']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_filtered['data_set'] = \"moh_x\"\n",
    "\n",
    "moh_x_df = df_filtered[['sentence', 'data_set', 'masked_sentence']]\n",
    "moh_x_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               index  label  \\\n",
      "0  a3m-fragment02 45      0   \n",
      "1  a3m-fragment02 45      1   \n",
      "2  a3m-fragment02 45      1   \n",
      "3  a3m-fragment02 45      0   \n",
      "4  a3m-fragment02 45      0   \n",
      "\n",
      "                                            sentence    POS FGPOS  w_index  \n",
      "0  Design : Crossed lines over the toytown tram :...   NOUN    NN        0  \n",
      "1  Design : Crossed lines over the toytown tram :...   VERB   VBN        2  \n",
      "2  Design : Crossed lines over the toytown tram :...   NOUN   NNS        3  \n",
      "3  Design : Crossed lines over the toytown tram :...  PROPN   NNP        6  \n",
      "4  Design : Crossed lines over the toytown tram :...  PROPN   NNP        7  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>data_set</th>\n",
       "      <th>masked_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Design : Crossed lines over the toytown tram :...</td>\n",
       "      <td>vua</td>\n",
       "      <td>Design : [MASK] lines over the toytown tram : ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>They also exert a fascination very much of the...</td>\n",
       "      <td>vua</td>\n",
       "      <td>They also [MASK] a fascination very much of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>They also exert a fascination very much of the...</td>\n",
       "      <td>vua</td>\n",
       "      <td>They also exert a fascination very much of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Eventually they will be replaced , but more th...</td>\n",
       "      <td>vua</td>\n",
       "      <td>Eventually they will be replaced , but more th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Destined to run in Manchester , they will reli...</td>\n",
       "      <td>vua</td>\n",
       "      <td>[MASK] to run in Manchester , they will reliev...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence data_set  \\\n",
       "1   Design : Crossed lines over the toytown tram :...      vua   \n",
       "35  They also exert a fascination very much of the...      vua   \n",
       "38  They also exert a fascination very much of the...      vua   \n",
       "70  Eventually they will be replaced , but more th...      vua   \n",
       "91  Destined to run in Manchester , they will reli...      vua   \n",
       "\n",
       "                                      masked_sentence  \n",
       "1   Design : [MASK] lines over the toytown tram : ...  \n",
       "35  They also [MASK] a fascination very much of th...  \n",
       "38  They also exert a fascination very much of the...  \n",
       "70  Eventually they will be replaced , but more th...  \n",
       "91  [MASK] to run in Manchester , they will reliev...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = [\"data/test.tsv\",\"data/train.tsv\"]\n",
    "df_list = [pd.read_csv(filename, sep='\\t') for filename in all_files]\n",
    "\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "print(df.head())\n",
    "\n",
    "# Filter for rows where label == 1 and apply masking\n",
    "df_filtered = df[(df['label'] == 1) & (df['POS'] == 'VERB')].copy()\n",
    "df_filtered['masked_sentence'] = df_filtered.apply(\n",
    "    lambda row: mask_word(row['sentence'], row['w_index']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_filtered['data_set'] = \"vua\"\n",
    "\n",
    "vua_df = df_filtered[['sentence', 'data_set', 'masked_sentence']]\n",
    "vua_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([vua_df, trofi_df, moh_x_df], ignore_index=True)\n",
    "#combined_df.to_csv(\"data/combined_dataframe.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combined_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      masked_word data_set\n",
      "0         Crossed      vua\n",
      "1           exert      vua\n",
      "2         slither      vua\n",
      "3             run      vua\n",
      "4        Destined      vua\n",
      "...           ...      ...\n",
      "22807          of    moh_x\n",
      "22808          in    moh_x\n",
      "22809        None    moh_x\n",
      "22810         the    moh_x\n",
      "22811           a    moh_x\n",
      "\n",
      "[22812 rows x 2 columns]\n",
      "data_set\n",
      "moh_x     217\n",
      "trofi     233\n",
      "vua      1873\n",
      "Name: masked_word, dtype: int64\n",
      "     data_set masked_word  count\n",
      "0       moh_x        $100      1\n",
      "1       moh_x      Africa      1\n",
      "2       moh_x      Bosnia      1\n",
      "3       moh_x           a      2\n",
      "4       moh_x       about      1\n",
      "...       ...         ...    ...\n",
      "2318      vua       woven      2\n",
      "2319      vua    wreathed      1\n",
      "2320      vua     written      1\n",
      "2321      vua       wrung      2\n",
      "2322      vua    yielding      3\n",
      "\n",
      "[2323 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def extract_masked_word(row):\n",
    "    original_words = row['sentence'].split()\n",
    "    masked_words = row['masked_sentence'].replace('[MASK]', '').split()\n",
    "    # Find the word in `original_words` that's not in `masked_words`\n",
    "    return next((word for word in original_words if word not in masked_words), None)\n",
    "\n",
    "df['masked_word'] = df.apply(extract_masked_word, axis=1)\n",
    "\n",
    "# Count unique masked words grouped by `data_set`\n",
    "unique_masked_counts = df.groupby('data_set')['masked_word'].nunique()\n",
    "\n",
    "print(df[['masked_word', 'data_set']])\n",
    "print(unique_masked_counts)\n",
    "unique_masked_word_counts = df.groupby(['data_set', 'masked_word']).size().reset_index(name='count')\n",
    "print(unique_masked_word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_set</th>\n",
       "      <th>masked_word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>moh_x</td>\n",
       "      <td>the</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>moh_x</td>\n",
       "      <td>with</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>moh_x</td>\n",
       "      <td>his</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>moh_x</td>\n",
       "      <td>to</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>moh_x</td>\n",
       "      <td>her</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>moh_x</td>\n",
       "      <td>absorbed</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>moh_x</td>\n",
       "      <td>in</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>moh_x</td>\n",
       "      <td>into</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>moh_x</td>\n",
       "      <td>on</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>moh_x</td>\n",
       "      <td>clawed</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>trofi</td>\n",
       "      <td>stepped</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>trofi</td>\n",
       "      <td>step</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>trofi</td>\n",
       "      <td>roll</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>trofi</td>\n",
       "      <td>stuck</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>trofi</td>\n",
       "      <td>killed</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>trofi</td>\n",
       "      <td>struck</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>trofi</td>\n",
       "      <td>cool</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>trofi</td>\n",
       "      <td>sleep</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>trofi</td>\n",
       "      <td>pumping</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>trofi</td>\n",
       "      <td>stick</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>vua</td>\n",
       "      <td>make</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>vua</td>\n",
       "      <td>made</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>vua</td>\n",
       "      <td>got</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>vua</td>\n",
       "      <td>see</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>vua</td>\n",
       "      <td>take</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>vua</td>\n",
       "      <td>go</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>vua</td>\n",
       "      <td>come</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>vua</td>\n",
       "      <td>put</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>vua</td>\n",
       "      <td>give</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2183</th>\n",
       "      <td>vua</td>\n",
       "      <td>took</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     data_set masked_word  count\n",
       "196     moh_x         the     18\n",
       "212     moh_x        with     11\n",
       "118     moh_x         his      7\n",
       "200     moh_x          to      6\n",
       "116     moh_x         her      5\n",
       "5       moh_x    absorbed      4\n",
       "123     moh_x          in      4\n",
       "129     moh_x        into      4\n",
       "154     moh_x          on      4\n",
       "57      moh_x      clawed      3\n",
       "410     trofi     stepped    500\n",
       "409     trofi        step    450\n",
       "391     trofi        roll    400\n",
       "425     trofi       stuck    390\n",
       "328     trofi      killed    330\n",
       "423     trofi      struck    270\n",
       "234     trofi        cool    260\n",
       "397     trofi       sleep    250\n",
       "368     trofi     pumping    240\n",
       "413     trofi       stick    240\n",
       "1509      vua        make    115\n",
       "1504      vua        made    102\n",
       "1286      vua         got     99\n",
       "1926      vua         see     92\n",
       "2144      vua        take     88\n",
       "1280      vua          go     76\n",
       "824       vua        come     71\n",
       "1738      vua         put     61\n",
       "1272      vua        give     58\n",
       "2183      vua        took     51"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_masked_words = unique_masked_word_counts.sort_values(\n",
    "    ['data_set', 'count'], ascending=[True, False]\n",
    ").groupby('data_set').head(10)\n",
    "top_10_masked_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_replaced_word(row):\n",
    "    original_words = row['sentence'].split()\n",
    "    masked_words = row['masked_sentence'].split()\n",
    "    for orig, masked in zip(original_words, masked_words):\n",
    "        if masked == '[MASK]':\n",
    "            return orig\n",
    "    return None\n",
    "\n",
    "df['replaced_word'] = df.apply(extract_replaced_word, axis=1)\n",
    "\n",
    "top_10_per_dataset = (\n",
    "    df.groupby('data_set')['replaced_word']\n",
    "    .value_counts()\n",
    "    .groupby(level=0, group_keys=False)  \n",
    "    .nlargest(10) \n",
    "    .reset_index(name='count')  \n",
    ")\n",
    "\n",
    "top_10_per_dataset['normalized_count'] = (\n",
    "    top_10_per_dataset.groupby('data_set')['count']\n",
    "    .transform(lambda x: x / x.sum())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_per_dataset[top_10_per_dataset[\"data_set\"] == \"moh_x\"].to_csv('top_10_in_dataset_moh_x.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_per_dataset[top_10_per_dataset[\"data_set\"] == \"vua\"].reset_index().drop(columns='index').to_csv('top_10_in_dataset_vua.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_per_dataset[top_10_per_dataset[\"data_set\"] == \"trofi\"].reset_index().drop(columns='index').to_csv('top_10_in_dataset_trofi.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
