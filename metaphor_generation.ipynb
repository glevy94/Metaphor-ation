{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments, BartForConditionalGeneration, BartTokenizer\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "from datasets import Dataset\n",
    "\n",
    "# set GPU device\n",
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New DataFrame variables created:\n",
      "vua_df\n",
      "trofi_df\n",
      "moh_x_df\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "combined_df = pd.read_csv(\"data/combined_dataframe.csv\")\n",
    "\n",
    "dataset_names = combined_df[\"data_set\"].unique()\n",
    "\n",
    "df_names = []\n",
    "for name in dataset_names:\n",
    "\n",
    "    df_name = f\"{name}_df\"\n",
    "\n",
    "    globals()[f\"{df_name}\"] = (\n",
    "        combined_df[combined_df[\"data_set\"] == name]\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    df_names.append(df_name)\n",
    "\n",
    "\n",
    "print(\"New DataFrame variables created:\")\n",
    "for df_name in df_names:\n",
    "    print(df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vua_df = vua_df # type: ignore\n",
    "trofi_df = trofi_df # type: ignore\n",
    "moh_x_df = moh_x_df # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data set to train on\n",
    "\n",
    "dataset = Dataset.from_pandas(vua_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00a643964844e16a8fcfb5f001475b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6227 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb3d5b7b9a54451b53080ebda81b5c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2693, 'grad_norm': 0.3655458092689514, 'learning_rate': 0.0014615384615384616, 'epoch': 0.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff288bc711b468a97be7fad56d87cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14250056445598602, 'eval_runtime': 3.4331, 'eval_samples_per_second': 90.879, 'eval_steps_per_second': 11.36, 'epoch': 1.0}\n",
      "{'train_runtime': 198.1592, 'train_samples_per_second': 31.424, 'train_steps_per_second': 0.984, 'train_loss': 0.2311469933925531, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=195, training_loss=0.2311469933925531, metrics={'train_runtime': 198.1592, 'train_samples_per_second': 31.424, 'train_steps_per_second': 0.984, 'total_flos': 452060831539200.0, 'train_loss': 0.2311469933925531, 'epoch': 1.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model_name = \"google/flan-t5-small\" \n",
    "model_t5 = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "tokenizer_t5 = T5Tokenizer.from_pretrained(model_name, legacy=False, clean_up_tokenization_spaces=True)\n",
    "\n",
    "# Add [MASK] token if not already present\n",
    "if \"[MASK]\" not in tokenizer_t5.get_vocab():\n",
    "    tokenizer_t5.add_tokens(\"[MASK]\")\n",
    "    model_t5.resize_token_embeddings(len(tokenizer_t5))  # Resize embeddings to match the updated vocab size\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    prompt = \"Replace [MASK] to create metaphor sentence: {masked_sentence}\"\n",
    "\n",
    "    inputs = [\n",
    "        prompt.format(masked_sentence=sentence)\n",
    "        for sentence in examples['masked_sentence']\n",
    "    ]\n",
    "    \n",
    "    targets = examples['sentence']\n",
    "    \n",
    "    model_inputs = tokenizer_t5(inputs, max_length=200, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer_t5(targets, max_length=200, truncation=True, padding=\"max_length\")[\"input_ids\"]\n",
    "    labels = [[-100 if token == tokenizer_t5.pad_token_id else token for token in label] for label in labels]\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels\n",
    "\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# dataset split to verify model works\n",
    "dataset_split = tokenized_dataset.train_test_split(test_size=0.05, seed=42)\n",
    "eval_dataset = dataset_split['test']\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=32,\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=100,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_t5,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data set to train on\n",
    "\n",
    "dataset = Dataset.from_pandas(vua_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5344bc8635b149a78fe422333c58164f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d49c8d5ef24c44851a173d595b6785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758e48611b65470aa24afa176fdb97ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6227 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5bcb096b177495caa38142e2e48800a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3051, 'grad_norm': 0.733235776424408, 'learning_rate': 0.00014615384615384615, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e384245892234db88a4da3cec9c569a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09412288665771484, 'eval_runtime': 5.6577, 'eval_samples_per_second': 55.146, 'eval_steps_per_second': 6.893, 'epoch': 1.0}\n",
      "{'train_runtime': 390.8523, 'train_samples_per_second': 15.932, 'train_steps_per_second': 0.499, 'train_loss': 0.2376271712474334, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=195, training_loss=0.2376271712474334, metrics={'train_runtime': 390.8523, 'train_samples_per_second': 15.932, 'train_steps_per_second': 0.499, 'total_flos': 741568149504000.0, 'train_loss': 0.2376271712474334, 'epoch': 1.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model_name = \"facebook/bart-base\"  # Use BART model\n",
    "model_bart = BartForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "tokenizer_bart = BartTokenizer.from_pretrained(model_name, clean_up_tokenization_spaces=True)\n",
    "\n",
    "# Add [MASK] token if not already present (optional for BART)\n",
    "if \"[MASK]\" not in tokenizer_bart.get_vocab():\n",
    "    tokenizer_bart.add_tokens(\"[MASK]\")\n",
    "    model_bart.resize_token_embeddings(len(tokenizer_bart))  # Resize embeddings to match updated vocab size\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    prompt = \"Replace [MASK] to create metaphor sentence: {masked_sentence}\"\n",
    "    \n",
    "    # Prepare inputs and targets\n",
    "    inputs = [\n",
    "        prompt.format(masked_sentence=sentence)\n",
    "        for sentence in examples['masked_sentence']\n",
    "    ]\n",
    "    targets = examples['sentence']\n",
    "    \n",
    "    # Tokenize inputs and targets\n",
    "    model_inputs = tokenizer_bart(inputs, max_length=200, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer_bart(targets, max_length=200, truncation=True, padding=\"max_length\")[\"input_ids\"]\n",
    "    labels = [[-100 if token == tokenizer_bart.pad_token_id else token for token in label] for label in labels]\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "# tokenize dataset\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Eval set for confirming model fit\n",
    "dataset_split = tokenized_dataset.train_test_split(test_size=0.05, seed=42)\n",
    "eval_dataset = dataset_split['test']\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=32,  # Adjust batch size for memory constraints\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=100,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_bart,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To be updated\n",
    "'''\n",
    "\n",
    "synthetic_sentences = [\n",
    "    \"The sun [MASK] across the sky, painting the horizon in gold.\",\n",
    "    \"Her voice [MASK] like a gentle breeze on a summer day.\",\n",
    "    \"The old car [MASK] down the road, coughing with every mile.\",\n",
    "    \"The tree [MASK] its arms to the heavens, yearning for light.\",\n",
    "    \"The river [MASK] its way through the valley, carving stories in the earth.\",\n",
    "    \"The city [MASK] with life as the morning light crept in.\",\n",
    "    \"His words [MASK] into her heart like arrows from a bow.\",\n",
    "    \"The night sky [MASK] with a blanket of shimmering stars.\",\n",
    "    \"The storm [MASK] its fury across the land, leaving chaos in its wake.\",\n",
    "    \"The clock [MASK] away the seconds, a steady heartbeat in the silence.\",\n",
    "    \"The fire [MASK] in the hearth, whispering tales of warmth and comfort.\",\n",
    "    \"The child [MASK] through the field, chasing butterflies of her imagination.\",\n",
    "    \"The mountain [MASK] in silent majesty, watching over the valley.\",\n",
    "    \"The wind [MASK] its way through the trees, singing a mournful tune.\",\n",
    "    \"His laughter [MASK] the room, lighting up every corner.\",\n",
    "    \"The ink [MASK] across the paper, leaving trails of forgotten thoughts.\",\n",
    "    \"The skyscrapers [MASK] into the sky, defying the pull of the earth.\",\n",
    "    \"Her shadow [MASK] behind her, clinging like an unspoken regret.\",\n",
    "    \"The book [MASK] stories into the minds of those who dared to read.\",\n",
    "    \"The horizon [MASK] the sea and sky in an eternal embrace.\",\n",
    "    \"The storm clouds [MASK] a curtain of darkness over the town.\",\n",
    "    \"The clock [MASK] its relentless march, indifferent to human desire.\",\n",
    "    \"His ambition [MASK] like wildfire, consuming everything in its path.\",\n",
    "    \"The melody [MASK] through the air, weaving an invisible tapestry of sound.\",\n",
    "    \"The bridge [MASK] the chasm, uniting what was once divided.\",\n",
    "    \"The city lights [MASK] the darkness, a sea of artificial stars.\",\n",
    "    \"Her tears [MASK] rivers down her cheeks, carving paths of sorrow.\",\n",
    "    \"The wind [MASK] secrets through the cracks of the ancient walls.\",\n",
    "    \"The mountain's peak [MASK] the heavens, shrouded in a veil of clouds.\",\n",
    "    \"The forest [MASK] a labyrinth of shadows, hiding untold mysteries.\",\n",
    "    \"The stars above [MASK] in patterns that whispered ancient secrets to the dreamers below.\",\n",
    "    \"The artist's brush [MASK] across the canvas, leaving behind strokes of vibrant emotion.\",\n",
    "    \"As the river flowed, its surface [MASK] the sky in a shimmering dance of light.\",\n",
    "    \"Her laughter [MASK] through the quiet room, breaking the stillness with its melody.\",\n",
    "    \"The old house, forgotten by time, [MASK] stories of those who once lived within its walls.\",\n",
    "    \"The forest's shadows [MASK] over the path, creating a maze of darkness and light.\",\n",
    "    \"The city streets [MASK] with echoes of footsteps as the night grew older.\",\n",
    "    \"The candle's flame [MASK] against the cold air, a fragile beacon in the dark.\",\n",
    "    \"His words, though soft, [MASK] deep into the hearts of those who listened.\",\n",
    "    \"The distant mountains [MASK] a hazy blue in the fading light of dusk.\",\n",
    "    \"The clock on the wall [MASK] a steady rhythm, marking the passage of time.\",\n",
    "    \"As the wind passed, it [MASK] the leaves into a delicate, rustling symphony.\",\n",
    "    \"The clouds [MASK] their shadows over the fields, shifting as the sun moved.\",\n",
    "    \"The silence of the library [MASK] with the weight of unwritten stories and untold knowledge.\",\n",
    "    \"The waves [MASK] the shore, pulling back only to return with renewed vigor.\",\n",
    "    \"The room [MASK] with a faint scent of lavender as she walked in.\",\n",
    "    \"He [MASK] the page, his eyes scanning for something he couldnâ€™t quite define.\",\n",
    "    \"The train [MASK] the station at precisely 9:00 AM, as it always did.\",\n",
    "    \"Her voice [MASK] through the conversation, quiet but firm.\",\n",
    "    \"The door [MASK] softly as it closed behind him, leaving the room in silence.\",\n",
    "    \"The floorboards [MASK] under his weight, a reminder of the house's age.\",\n",
    "    \"The coffee [MASK] on the counter, untouched and growing cold.\",\n",
    "    \"He [MASK] the glass, staring out at the rain without seeing it.\",\n",
    "    \"The email [MASK] in her inbox, waiting for her reply.\",\n",
    "    \"The crowd [MASK] as the speaker walked to the podium.\",\n",
    "    \"The light from the window [MASK] across the desk, illuminating the open book.\",\n",
    "    \"She [MASK] the scarf tighter around her neck, bracing against the cold.\",\n",
    "    \"The papers [MASK] across the table, some slipping to the floor.\",\n",
    "    \"The clock [MASK] on the wall, its ticking filling the quiet room.\",\n",
    "    \"The car [MASK] in the driveway, engine running but going nowhere.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompts(sentence: str, method: str ) -> str:\n",
    "    \"\"\"\n",
    "    Creates prompt for input to generate method\n",
    "\n",
    "    Args:\n",
    "        sentence (str): Masked sentence\n",
    "        method (str): \"zero\" for zero shot \"few\" for few shot\n",
    "\n",
    "    Returns:\n",
    "        Prompt for input to generate method\n",
    "    \"\"\"\n",
    "\n",
    "    # Few-shot example\n",
    "    few_shot_examples = \"\"\"\n",
    "    Transform the following literal sentences into metaphorical ones by replacing [MASK]:\n",
    "\n",
    "    Input: The task is [MASK] challenging.\n",
    "    Output: The task is an uphill battle.\n",
    "\n",
    "    Input: She is [MASK] sad.\n",
    "    Output: She is drowning in sorrow.\n",
    "\n",
    "    Input: He is [MASK] angry.\n",
    "    Output: He is a volcano about to erupt.\n",
    "    \"\"\"\n",
    "\n",
    "    # Zero-shot example\n",
    "    zero_shot_example = \"\"\"\n",
    "    Transform the following literal sentence into metaphorical ones by replacing [MASK]:\n",
    "    \"\"\"\n",
    "\n",
    "    if method == \"zero\":\n",
    "        prompt = zero_shot_example + f\" {sentence}\"\n",
    "    if method == \"few\":\n",
    "        prompt = few_shot_examples + f\"\\nInput: {sentence}\\nOutput:\"\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_metaphors(model, tokenizer, sentences: list[str], prompt_type: str = \"few\", view_output: bool = False, ) -> list[str]: # type: ignore\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates metaphor sentences from masked sentences\n",
    "\n",
    "    Args:\n",
    "        model: pre-trained model\n",
    "        tokenizer: model tokenizer\n",
    "        sentences (list): list of sentences to transform\n",
    "        prompt_type (str): \"zero\" for zero shot \"few\" for few shot\n",
    "        view_output (bool): set true to print masked sentences and generated metaphor\n",
    "        \n",
    "    Returns:\n",
    "        A list of transformed sentences\n",
    "    \"\"\"\n",
    "    \n",
    "    model = model.to(device)\n",
    "    output = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "\n",
    "        prompt = prompts(sentence, prompt_type)\n",
    "\n",
    "        # Tokenize and move to the device\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "        # Generate the output\n",
    "        output_ids = model.generate(\n",
    "            inputs=input_ids[\"input_ids\"],  \n",
    "            max_length=150,                # Allow for longer outputs\n",
    "            num_beams=5,                  \n",
    "            do_sample=True,\n",
    "            temperature=1.2,               # Slightly higher temperature for creativity\n",
    "            top_k=50,                      # Use top-k sampling to encourage variation\n",
    "            top_p=0.8,                     # Use nucleus sampling for creativity\n",
    "            early_stopping=False\n",
    "        )\n",
    "\n",
    "        # Decode and print the output\n",
    "        output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        output.append(output_text)\n",
    "\n",
    "        if view_output is True:\n",
    "            print(f\"Input: {sentence}\\nOutput: {output_text}\\n\")\n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: The sun [MASK] across the sky, painting the horizon in gold.\n",
      "Output: The sun swept across the sky, painting the horizon in gold.\n",
      "\n",
      "Input: Her voice [MASK] like a gentle breeze on a summer day.\n",
      "Output: Her voice rose like a gentle breeze on a summer day.\n",
      "\n",
      "Input: The old car [MASK] down the road, coughing with every mile.\n",
      "Output: The old car ran down the road, coughing with every mile.\n",
      "\n",
      "Input: The tree [MASK] its arms to the heavens, yearning for light.\n",
      "Output: The tree made its arms to the heavens, yearning for light.\n",
      "\n",
      "Input: The river [MASK] its way through the valley, carving stories in the earth.\n",
      "Output: The river took its way through the valley, carving stories in the earth.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The sun swept across the sky, painting the horizon in gold.',\n",
       " 'Her voice rose like a gentle breeze on a summer day.',\n",
       " 'The old car ran down the road, coughing with every mile.',\n",
       " 'The tree made its arms to the heavens, yearning for light.',\n",
       " 'The river took its way through the valley, carving stories in the earth.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_output = generate_metaphors(model=model_t5,tokenizer=tokenizer_t5, sentences=synthetic_sentences[:5], prompt_type=\"zero\", view_output=True)\n",
    "t5_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: The sun [MASK] across the sky, painting the horizon in gold.\n",
      "Output: Pursuing Transform the following literal sentence into metaphorical ones by replacing left-over faded across the sky, painting the horizon in gold.\n",
      "\n",
      "Input: Her voice [MASK] like a gentle breeze on a summer day.\n",
      "Output: Hang like a gentle breeze on a summer day.\n",
      "\n",
      "Input: The old car [MASK] down the road, coughing with every mile.\n",
      "Output: Turning the following literal sentence into metaphorical ones by replacing the old car running down the road, coughing with every mile.\n",
      "\n",
      "Input: The tree [MASK] its arms to the heavens, yearning for light.\n",
      "Output: Turning its arms to the heavens, yearning for light.\n",
      "\n",
      "Input: The river [MASK] its way through the valley, carving stories in the earth.\n",
      "Output: pursuing its way through the valley, carving stories in the earth.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Pursuing Transform the following literal sentence into metaphorical ones by replacing left-over faded across the sky, painting the horizon in gold.',\n",
       " 'Hang like a gentle breeze on a summer day.',\n",
       " 'Turning the following literal sentence into metaphorical ones by replacing the old car running down the road, coughing with every mile.',\n",
       " 'Turning its arms to the heavens, yearning for light.',\n",
       " 'pursuing its way through the valley, carving stories in the earth.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart_output = generate_metaphors(model=model_bart,tokenizer=tokenizer_bart, sentences=synthetic_sentences[:5], prompt_type=\"zero\", view_output=True)\n",
    "bart_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
